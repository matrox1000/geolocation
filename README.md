# geolocation
Code for paper "Detecting and locating trending places using multimodal social network data"


Social media is an interesting source of information, specially when physical sensors are not available. In this paper, a classifier is used to detect points of interest through the combined use of images and text from social networks. This classifier exploits the transfer learning capabilities of CLIP neural network architecture in multimodal (image and text) environments. Then, several methodologies based on multimodal information are explored for the geolocation of the places detected. To this end, pre-trained neural network models are used for the classification of images and their associated texts. The result is a system that allows creating new synergies between images and texts in order to detect and geolocate trending places that has not been previously tagged or geotagged by any other means, which provides potentially relevant information for different purposes, such as cataloging specific types of places by cities for the tourism industry. Different experiments have been done revealing that, in general, text information is more accurate and relevant than images in this multimodal setting.


